

üß© FinTech AI Assistant ‚Äî Key Testing Areas (as defined by the Product Manager)
You are a Product Manager for a FinTech company that‚Äôs developing an AI-based assistant (chatbot) similar to ChatGPT.The assistant uses a large language model (LLM) to help customers with questions related to the company‚Äôs products, services, and financial tools.
As Product Manager, you‚Äôve identified core functional and non-functional testing areas that must be validated before deployment.You‚Äôre now presenting these to the LLM Tester (me) to design detailed evaluation plans and prompt-based tests.

1. Domain Knowledge & Financial Accuracy
	‚Ä¢	Evaluate the assistant‚Äôs understanding of key financial concepts: interest rates, APR, credit scores, investment risk, account types, etc.
	‚Ä¢	Test for accuracy when explaining company-specific products or comparing product tiers.
	‚Ä¢	Check for hallucinations or fabrication of nonexistent products.

2. Regulatory & Compliance Adherence
	‚Ä¢	Ensure the assistant never gives personalized investment or lending advice.
	‚Ä¢	Validate correct usage of disclaimers (e.g., ‚ÄúThis does not constitute financial advice‚Äù).
	‚Ä¢	Test for compliance with local and global frameworks (e.g., GDPR, KYC, AML).
	‚Ä¢	Evaluate how it handles requests for sensitive data ‚Äî should reject or redirect.

3. Product Navigation & Troubleshooting Support
	‚Ä¢	Verify that the assistant can guide users through app or web portal processes (e.g., applying for a loan, resetting passwords).
	‚Ä¢	Check contextual understanding of multi-step processes (e.g., loan application steps).
	‚Ä¢	Test troubleshooting flows for common user issues.

4. Customer Service & Empathy Handling
	‚Ä¢	Assess emotional tone and empathy in responses to upset or anxious users.
	‚Ä¢	Ensure balance between professionalism and friendliness.
	‚Ä¢	Simulate edge cases like declined transactions or fraud reports.

5. Conversational Context & Memory Management
	‚Ä¢	Check if the assistant can maintain conversation context within a session.
	‚Ä¢	Validate correct referencing of prior messages (no contradictions or forgotten info).
	‚Ä¢	Ensure no persistence of personal data after session ends.

6. Personalization & Dynamic Adaptation
	‚Ä¢	Evaluate ability to tailor responses to user segments (e.g., new vs. premium customer).
	‚Ä¢	Test whether tone and recommendations adapt appropriately.
	‚Ä¢	Confirm personalization boundaries ‚Äî it must not infer or assume data beyond session context.

7. Data Privacy & Security Controls
	‚Ä¢	Test resistance to prompt injection or attempts to extract system prompts.
	‚Ä¢	Ensure refusal to share internal or confidential business data.
	‚Ä¢	Evaluate redaction of sensitive inputs like SSNs, account numbers, or card details.

8. Transparency & Explainability
	‚Ä¢	Verify that the assistant can explain how it arrived at an answer (where applicable).
	‚Ä¢	Test self-correction behavior: when it‚Äôs unsure, it should acknowledge uncertainty rather than fabricate.

9. Performance & Reliability
	‚Ä¢	Evaluate latency, uptime, and error-handling resilience.
	‚Ä¢	Simulate high-traffic conditions.
	‚Ä¢	Test retry logic, fallback responses, and graceful degradation under load.

10. Multimodal and Multichannel Consistency
	‚Ä¢	Verify behavior consistency across web chat, mobile app, and voice interface.
	‚Ä¢	Test response equivalence for identical queries in different channels.

11. Ethical & Fairness Testing
	‚Ä¢	Ensure no bias in responses related to gender, ethnicity, or socioeconomic status.
	‚Ä¢	Test how the model responds to sensitive financial eligibility topics (e.g., loan denials).

12. User Education & Proactive Guidance
	‚Ä¢	Assess ability to provide educational content on financial literacy topics (e.g., budgeting, credit building).
	‚Ä¢	Evaluate clarity and simplicity of explanations for novice users.

üí° Next step for the LLM Tester:For each testing area, design evaluation prompts, expected behaviors, and grading metrics (e.g., accuracy, compliance, empathy, latency).The goal is to convert these key areas into structured prompt tests and evaluation sets that can be run in tools like Promptfoo, TruLens, or Evalute.
